%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Medium Length Professional CV
% LaTeX Template
% Version 2.0 (8/5/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Trey Hunner (http://www.treyhunner.com/)
%
% Important note:
% This template requires the resume.cls file to be in the same directory as the
% .tex file. The resume.cls file provides the resume style used for structuring the
% document.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{resume} % Use the custom resume.cls style

\usepackage[left=0.4 in,top=0.4in,right=0.4 in,bottom=0.4in]{geometry} % Document margins
\newcommand{\tab}[1]{\hspace{.2667\textwidth}\rlap{#1}} 
\newcommand{\itab}[1]{\hspace{0em}\rlap{#1}}
\name{HENGGANG CUI} % Your name
\address{2220A, Collaborative Innovation Center, 5000 Forbes Ave, Pittsburgh, PA, 15213.} % Your address
%\address{123 Pleasant Lane \\ City, State 12345} % Your secondary addess (optional)
\address{(651)403-3366 \\ hengganc@andrew.cmu.edu}  % Your phone number and email

\begin{document}

%----------------------------------------------------------------------------------------
%	OBJECTIVE
%----------------------------------------------------------------------------------------

% \begin{rSection}{OBJECTIVE}

% {Recently graduated, multidisciplinary Engineer with excellent problem solving abilities and process-thinking skill seeks hands on experience within a company that embraces creativity and innovation.Through my studies, I have gained extensive knowledge of production and manufacturing engineering, product design, among many other components of  Mechanical Engineering.Effective communicator who builds positive, cohesive relationship with all level of staff, eager to put my extensive studies to practical, applied use.}


% \end{rSection}
%----------------------------------------------------------------------------------------
%	EDUCATION SECTION
%----------------------------------------------------------------------------------------

\begin{rSection}{Education}

\begin{rSubsection}{Carnegie Mellon University, Pittsburgh, PA.}{}{}{}
\item[] Ph.D., Electrical and Computer Engineering \hfill \emph{Expected:} May, 2017
\item Advisor: Greg Ganger
\item Research Topic: System Support for Large-Scale Machine Learning
\item Thesis: Exploiting Application Characteristics for Efficient System Support for Large-Scale Machine Learning
\end{rSubsection}
% \vspace{-.1in}

\begin{rSubsection}{Carnegie Mellon University, Pittsburgh, PA.}{}{}{}
\item[] Master of Science, Electrical and Computer Engineering, \hfill May, 2016
\end{rSubsection}
% \vspace{-.1in}

\begin{rSubsection}{Tsinghua University, Beijing, China}{}{}{}
\item[] Bachelor of Science, Electronic Information Science and Technology, \hfill July 2012
\end{rSubsection}
% \vspace{-.1in}

\end{rSection}
%----------------------------------------------------------------------------------------
%	TECHNICAL STRENGTHS SECTION
%----------------------------------------------------------------------------------------

\begin{rSection}{SKILLS}

\begin{tabular}{ @{} >{\bfseries}l @{\hspace{6ex}} l }
Programming languages & C$+$$+$, Python, C, Java, CUDA, Matlab, Shell\\
Software Systems & Git, Linux, LaTeX, SVN\\  
Big data Systems & Caffe, GraphLab, MPI, Spark, HBase, OpenTSDB, Hadoop\\
\end{tabular}

\end{rSection}

%----------------------------------------------------------------------------------------
%	WORK EXPERIENCE SECTION
%----------------------------------------------------------------------------------------

\begin{rSection}{RESEARCH PROJECTS}

\begin{rSubsection}{GeePS: Specialized Parameter Server for Deep Learning on GPUs}{}
{Published at EuroSys'16\\
Open-sourced at https://github.com/cuihenggang/geeps}{}
% \small{
\item Designed a parameter server system for distributed deep learning on a cluster of GPU machines.
\item Achieved good scalability from single-machine Caffe (13$\times$ more throughput with 16 machines), by overlapping communication with computation.
\item Support DNNs that do not fit in GPU memory, by swapping data to/from CPU memory in the background.
% }
\end{rSubsection}

\begin{rSubsection}{IterStore: Efficient Parameter Server for Iterative ML}{}
{Published at SoCC'14\\
Open-sourced at https://github.com/cuihenggang/iterstore}{}
% \small{
\item Observed the iterativeness characteristic of many ML applications: same access sequence every iterations.
\item Designed an efficient method for collecting the repeating access sequence.
\item Proposed five parameter server optimizations exploiting the collected information, including prefetching, contiguous marshalling-free data storage, locality and numa-aware data placement, and specialized caching policy.
\item Experimented with three real ML applications (matrix factorization, LDA, and PageRank) show that these optimizations reduce completion time by up to 50$\times$.
% }
\end{rSubsection}

\begin{rSubsection}{Stale Synchronous Parallel (SSP): Trading Data Freshness for Speed}{}
{Published at NIPS'13 and ATC'14}{}
\item SSP is a consistency model for synchronizing parallel ML workers, with tunable data staleness bound.
\item Designed a parameter server system supporting SSP, called LazyTable.
\item Experimented with many real ML applications, exploring the tradeoffs of data freshness and speed.
\end{rSubsection}

\pagebreak

\begin{rSubsection}{MLtuner: Automatic ML tuning}{}
{Work under submission}{}
\item Designed the MLtuner system that automatically tunes tunables for ML tasks, including learning rate, training batch size, and data staleness bound.
\item MLtuner uses efficient snapshotting and optimization-guided online trial-and-error to find good tunable settings.
\item Experiments with real ML tasks, including deep learning and matrix factorization, show that MLtuner automatically enables performance within 40--178\% of having oracle knowledge of the best tunable settings.
\end{rSubsection}

\end{rSection}


\begin{rSection}{INTERNSHIP PROJECTS}

\begin{rSubsection}{Aperture: Ingest-Time Transformation for Big Time Series Data}{}
{Internship project at HP Labs, advised by Kimberly Keeton\\
Published at SoCC'15}{}
\item Designed a database system, Aperture, for big time series data analytics.
\item Proposed the \emph{ingest-time transformation} approach that allows Aperture to answer analytical queries with transformed data, achieving much lower latencies.
\item Experimented with many real timeseries data analytics use cases, including correlation search, IP occurrence query, and anomaly detection, reducing query latencies by over an order of magnitude, with minimal impact on ingest throughput.
\end{rSubsection}

\end{rSection}


\begin{rSection}{PUBLICATIONS}
% \begin{bibsection}
    \item
    [1]
        {\bf Henggang Cui}, Hao Zhang, Gregory R. Ganger, Phillip B. Gibbons, and Eric P. Xing.
        GeePS: Scalable Deep Learning on Distributed GPUs with a GPU-Specialized Parameter Server.
        In \emph{ACM European Conference on Computer Systems (EuroSys'16)},
        2016.
        % \emph{Presented at conference}.
    \item
    [2]
        Aaron Harlap, {\bf Henggang Cui}, Wei Dai, Jinliang Wei,
        Gregory R. Ganger, Phillip B. Gibbons, Garth A. Gibson, and Eric P. Xing.
        Addressing the Straggler Problem for Iterative Convergent Parallel ML.
        In \emph{ACM Symposium on Cloud Computing (SoCC'16)},
        2016.
    \item
    [3]
        {\bf Henggang Cui}, Kimberly Keeton, Indrajit Roy, Krishnamurthy Viswanathan, and Gregory R. Ganger.
        Using Data Transformations for Low-latency Time Series Analysis.
        In \emph{ACM Symposium on Cloud Computing (SoCC'15)},
        2015.
        % \emph{Presented at conference}.
    \item
    [4]
        Jinliang Wei, Wei Dai, Aurick Qiao, Qirong Ho, {\bf Henggang Cui},
        Gregory R. Ganger, Phillip B. Gibbons, Garth A. Gibson, Eric P. Xing.
        Managed Communication and Consistency for Fast Data-Parallel Iterative Analytics.
        In \emph{ACM Symposium on Cloud Computing (SoCC'15)},
        2015.
    \item
    [5]
        {\bf Henggang Cui}, Alexey Tumanov, Jinliang Wei, Lianghong Xu, Wei Dai,
        Jesse Haber-Kucharsky, Qirong Ho, Gregory R. Ganger, Phillip B. Gibbons, Garth A. Gibson, and Eric P. Xing.
        Exploiting Iterative-ness for Parallel ML Computations.
        In \emph{ACM Symposium on Cloud Computing (SoCC'14)},
        2014.
        % \emph{Presented at conference}.
    \item
    [6]
        {\bf Henggang Cui}, James Cipar, Qirong Ho, Jin Kyu Kim, Seunghak Lee, Abhimanu Kumar,
        Jinliang Wei, Wei Dai, Gregory R. Ganger, Phillip B. Gibbons, Garth A. Gibson, and Eric P. Xing.
        Exploiting Bounded Staleness to Speed Up Big Data Analytics.
        In \emph{USENIX Annual Technical Conference (ATC'14)},
        2014.
        % \emph{Presented at conference}.
    \item
    [7]
        Qirong Ho, James Cipar, {\bf Henggang Cui}, Jin Kyu Kim, Seunghak Lee,
        Phillip B. Gibbons, Garth A. Gibson, Gregory R. Ganger, and Eric P. Xing.
        More Effective Distributed ML via a Stale Synchronous Parallel Parameter Server.
        In \emph{Neural Information Processing Systems (NIPS'13)},
        2013.
    \item
    [8]
        {\bf Henggang Cui}, Danielle Rasooly, Moises R. N. Ribeiro, and Leonid Kazovsky.
        Optically Cross-Braced Hypercube: A Reconfigurable Physical Layer for
        Interconnects and Server-Centric Datacenters.
        In \emph{Optical Fiber Communication Conference and Exposition (OFC/NFOEC)},
        2012.
    \item
    [9]
        Dan Li, {\bf Henggang Cui}, Yan Hu, Yong Xia, and Xin Wang.
        Scalable Data Center Multicast using Multi-class Bloom Filter.
        In \emph{19th IEEE International Conference on Network Protocols (ICNP'11)},
        2011.
% \end{bibsection}
\end{rSection}

\end{document}
